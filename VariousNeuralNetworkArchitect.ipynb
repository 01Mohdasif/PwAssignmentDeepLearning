{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1: Describe the basic structure of a Feedforward Neural Network (FNN). What is the purpose of the activation function?**\n",
        "# Answer: A Feedforward Neural Network (FNN) is composed of an input layer, one or more hidden layers, and an output layer.\n",
        "# Each layer contains nodes (neurons) that are connected to nodes in the previous and subsequent layers, forming a directed graph.\n",
        "# The data flows through the network in a forward direction, hence the name \"feedforward.\"\n",
        "#\n",
        "# Purpose of the Activation Function:\n",
        "# The activation function introduces non-linearity into the network. This enables the network to model complex patterns in the data.\n",
        "# Without the activation function, the network would be equivalent to a linear model, regardless of how many layers it has.\n",
        "# Common activation functions include ReLU, sigmoid, and tanh.\n"
      ],
      "metadata": {
        "id": "OxOErcPlvk1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: Explain the role of convolutional layers in a CNN. Why are pooling layers commonly used, and what do they achieve?**\n",
        "# Answer:\n",
        "# Convolutional Layers:\n",
        "# Convolutional layers in Convolutional Neural Networks (CNNs) are responsible for automatically detecting features in the input\n",
        "# data, such as edges, textures, and shapes in images. They apply convolution operations to local patches of the input data,\n",
        "# producing feature maps that capture spatial hierarchies.\n",
        "#\n",
        "# Pooling Layers:\n",
        "# Pooling layers are used after convolutional layers to reduce the spatial dimensions of the feature maps. This helps reduce\n",
        "# computational complexity, prevents overfitting, and increases the robustness of the network. Pooling operations, such as max\n",
        "# pooling or average pooling, aggregate information within local regions of the feature maps to extract the most important features.\n"
      ],
      "metadata": {
        "id": "YGTiyP2bvlPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: What is the key characteristic that differentiates Recurrent Neural Networks (RNNs) from other neural networks? How does an RNN handle sequential data?**\n",
        "# Answer: The key characteristic that differentiates Recurrent Neural Networks (RNNs) from other neural networks is their ability\n",
        "# to maintain a memory of previous inputs. RNNs have recurrent connections that allow them to process sequential data by passing\n",
        "# information from one step in the sequence to the next.\n",
        "#\n",
        "# Handling Sequential Data:\n",
        "# RNNs handle sequential data by maintaining hidden states that capture the context of previous inputs in the sequence.\n",
        "# This makes them suitable for tasks like time series forecasting, speech recognition, and natural language processing,\n",
        "# where the order of inputs is important.\n"
      ],
      "metadata": {
        "id": "VAEd_8XCvnQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: Discuss the components of a Long Short-Term Memory (LSTM) network. How does it address the vanishing gradient problem?**\n",
        "# Answer:\n",
        "# Components of an LSTM:\n",
        "# LSTM networks are a type of RNN designed to overcome the vanishing gradient problem. An LSTM consists of three main components:\n",
        "# 1. **Forget Gate:** Decides what information from the previous hidden state should be discarded.\n",
        "# 2. **Input Gate:** Determines what new information should be added to the memory.\n",
        "# 3. **Output Gate:** Decides what the current hidden state should output, which will be used in the next time step or layer.\n",
        "#\n",
        "# Addressing the Vanishing Gradient Problem:\n",
        "# LSTMs address the vanishing gradient problem by using a cell state that runs through the entire network with minimal\n",
        "# modifications. The gates regulate the flow of information, allowing the network to retain important long-term dependencies\n",
        "# while mitigating the vanishing gradient issue.\n"
      ],
      "metadata": {
        "id": "pDttM8ZOvqf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: Describe the roles of the generator and discriminator in a Generative Adversarial Network (GAN). What is the training objective for each?**\n",
        "# Answer:\n",
        "# Generator Role:\n",
        "# The generator's role in a GAN is to create fake data that is indistinguishable from real data. It takes random noise as input\n",
        "# and transforms it into synthetic data, such as images or text, that resembles the true data distribution.\n",
        "#\n",
        "# Discriminator Role:\n",
        "# The discriminator's role is to differentiate between real and fake data. It evaluates whether the data it receives is real\n",
        "# (from the actual data distribution) or fake (produced by the generator).\n",
        "#\n",
        "# Training Objectives:\n",
        "# - **Generator's Objective:** The generator aims to fool the discriminator by generating realistic fake data. It strives to\n",
        "# minimize the likelihood that the discriminator can correctly identify fake data.\n",
        "# - **Discriminator's Objective:** The discriminator aims to correctly classify data as real or fake. It strives to maximize\n",
        "# its ability to distinguish between real and generated data.\n"
      ],
      "metadata": {
        "id": "pR2Pa0Ysvr5v"
      }
    }
  ]
}